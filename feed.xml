<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://qmul-rg-fundamentals-of-ai.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://qmul-rg-fundamentals-of-ai.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-29T15:11:37+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Deep Learning is Not So Mysterious or Different</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/deep-learning-is-not-so-mysterious-or-different/" rel="alternate" type="text/html" title="Deep Learning is Not So Mysterious or Different"/><published>2025-04-09T10:30:00+00:00</published><updated>2025-04-09T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/deep-learning-is-not-so-mysterious-or-different</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/deep-learning-is-not-so-mysterious-or-different/"><![CDATA[<p><strong><a href="https://gmw99.github.io/">Gabryel Mason-Williams</a></strong> will presenting and dicussing the paper: Deep Learning is Not So Mysterious or Different <a class="citation" href="#wilson2025deeplearningmysteriousdifferent">(Wilson, 2025)</a></p> <p><strong><em>Abstract</em></strong></p> <p>Deep neural networks are often seen as different from other model classes by defying conventional notions of generalization. Popular examples of anomalous generalization behaviour include benign overfitting, double descent, and the success of overparametrization. We argue that these phenomena are not distinct to neural networks, or particularly mysterious. Moreover, this generalization behaviour can be intuitively understood, and rigorously characterized using long-standing generalization frameworks such as PAC-Bayes and countable hypothesis bounds. We present soft inductive biases as a key unifying principle in explaining these phenomena: rather than restricting the hypothesis space to avoid overfitting, embrace a flexible hypothesis space, with a soft preference for simpler solutions that are consistent with the data. This principle can be encoded in many model classes, and thus deep learning is not as mysterious or different from other model classes as it might seem. However, we also highlight how deep learning is relatively distinct in other ways, such as its ability for representation learning, phenomena such as mode connectivity, and its relative universality.</p>]]></content><author><name></name></author><category term="talks"/><category term="arxiv-paper"/><summary type="html"><![CDATA[Presented by Gabryel Mason-Williams]]></summary></entry><entry><title type="html">The Biophysical Principles Underlying Computation in Neural Substrates</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/the-biophysical-principles-underlying-computation-in-neural-substrates/" rel="alternate" type="text/html" title="The Biophysical Principles Underlying Computation in Neural Substrates"/><published>2025-03-12T10:30:00+00:00</published><updated>2025-03-12T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/the-biophysical-principles-underlying-computation-in-neural-substrates</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/the-biophysical-principles-underlying-computation-in-neural-substrates/"><![CDATA[<p><strong><a href="https://iranroman.github.io/">Iran Roman</a></strong> will presenting and dicussing the following:</p> <p><strong><em>Abstract</em></strong></p> <p>This presentation offers an overview of NeuroAI’s development, starting with seminal biophysical models such as the Hodgkin-Huxley equations, which elucidate the ionic mechanisms underlying neuronal action potentials. We then discuss the Wilson-Cowan model, capturing the interactions between excitatory and inhibitory neuronal populations. Advancements in the 2010s used recurrent neural networks to paralleling complex computations observed in both macaque and RNNs. We then discuss dynamical systems approaches, emphasizing their efficacy in modeling the temporal evolution of human brain activity, including unsupervised Hebbian Learning. Finally, we explore bifurcation theory’s role in identifying critical parameters that govern perception-action coupling within neural substrates, illustrating how minor variations can lead to significant shifts in neural computation.</p> <p><strong>Related Work</strong></p> <p><a class="citation" href="#mante2013context">(Mante et al., 2013)</a></p> <p><a class="citation" href="#zemlianova2024dynamical">(Zemlianova et al., 2024)</a></p> <p><a class="citation" href="#roman2023hebbian">(Roman et al., 2023)</a></p> <p><a class="citation" href="#driscoll2024flexible">(Driscoll et al., 2024)</a></p>]]></content><author><name></name></author><category term="talks"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Iran Roman]]></summary></entry><entry><title type="html">Approaching Deep Learning through the Spectral Dynamics of Weights</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/approaching-deep-learning-through-the-spectral-dynamics-of-weights/" rel="alternate" type="text/html" title="Approaching Deep Learning through the Spectral Dynamics of Weights"/><published>2025-02-26T10:30:00+00:00</published><updated>2025-02-26T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/approaching-deep-learning-through-the-spectral-dynamics-of-weights</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/approaching-deep-learning-through-the-spectral-dynamics-of-weights/"><![CDATA[<p><strong><a href="https://www.seresearch.qmul.ac.uk/cmai/people/msandler/">Mark Sandler</a></strong> will presenting and dicussing the the paper: Approaching Deep Learning through the Spectral Dynamics of Weights <a class="citation" href="#yunis2024approachingdeeplearningspectral">(Yunis et al., 2024)</a></p> <p><strong><em>Abstract</em></strong></p> <p>We propose an empirical approach centered on the spectral dynamics of weights—the behavior of singular values and vectors during optimization—to unify and clarify several phenomena in deep learning. We identify a consistent bias in optimization across various experiments, from small-scale ``grokking’’ to large-scale tasks like image classification with ConvNets, image generation with UNets, speech recognition with LSTMs, and language modeling with Transformers. We also demonstrate that weight decay enhances this bias beyond its role as a norm regularizer, even in practical systems. Moreover, we show that these spectral dynamics distinguish memorizing networks from generalizing ones, offering a novel perspective on this longstanding conundrum. Additionally, we leverage spectral dynamics to explore the emergence of well-performing sparse subnetworks (lottery tickets) and the structure of the loss surface through linear mode connectivity. Our findings suggest that spectral dynamics provide a coherent framework to better understand the behavior of neural networks across diverse settings.</p>]]></content><author><name></name></author><category term="talks"/><category term="arxiv-paper"/><summary type="html"><![CDATA[Presented by Mark Sandler]]></summary></entry><entry><title type="html">Explaining Transformers Using Model-Based Stochastic Signal Processing</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/explaining-transformers-using-model-based-stochastic-signal-processing/" rel="alternate" type="text/html" title="Explaining Transformers Using Model-Based Stochastic Signal Processing"/><published>2025-02-12T10:30:00+00:00</published><updated>2025-02-12T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/explaining-transformers-using-model-based-stochastic-signal-processing</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/explaining-transformers-using-model-based-stochastic-signal-processing/"><![CDATA[<p><strong><a href="https://uk.linkedin.com/in/careybunks">Carey Bunks</a></strong> will presenting their ongoing work on analysing Transformers</p> <p><strong><em>Abstract</em></strong></p> <p>This talk presents a novel analysis of Transformer components based on techniques drawn from model-based stochastic signal processing.  The proposed framework offers a theoretical foundation useful for mechanistic interpretability, and also suggests practical strategies for improving the performance of Transformer architectures.  Some preliminary experimental results will be presented.</p>]]></content><author><name></name></author><category term="talks"/><category term="ongoing-work"/><summary type="html"><![CDATA[Presented by Carey Bunks]]></summary></entry><entry><title type="html">NeurIPS 2024 Recap</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/neurips-recap/" rel="alternate" type="text/html" title="NeurIPS 2024 Recap"/><published>2025-01-29T10:30:00+00:00</published><updated>2025-01-29T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/neurips-recap</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/neurips-recap/"><![CDATA[<p><strong><a href="https://gmw99.github.io/">Gabryel Mason-Williams</a></strong> will be presenting about their time at NeurIPS 2024.</p> <p><strong><em>Abstract</em></strong></p> <p>This meeting will be a discussion on talks, papers etc, that Gabryel attend and saw that might be of interest to the group. It will be a broad range of papers and topics.</p>]]></content><author><name></name></author><category term="talks"/><category term="conference-update"/><summary type="html"><![CDATA[Presented by Gabryel Mason-Williams]]></summary></entry><entry><title type="html">Expressive Power of Temporal Message Passing</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/expressive-power-of-temporal-message-passing/" rel="alternate" type="text/html" title="Expressive Power of Temporal Message Passing"/><published>2024-12-04T10:30:00+00:00</published><updated>2024-12-04T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/expressive-power-of-temporal-message-passing</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/expressive-power-of-temporal-message-passing/"><![CDATA[<p><strong><a href="https://sites.google.com/site/pawalega/">Przemyslaw Walega</a></strong> will be presenting Expressive Power of Temporal Message Passing <a class="citation" href="#wałęga2024expressivepowertemporalmessage">(Wałęga &amp; Rawson, 2024)</a></p> <p><strong><em>Abstract</em></strong></p> <p>Graph neural networks (GNNs) have recently been adapted to temporal settings, often employing temporal versions of the message-passing mechanism known from GNNs. We divide temporal message passing mechanisms from literature into two main types: global and local, and establish Weisfeiler-Leman characterisations for both. This allows us to formally analyse expressive power of temporal message-passing models. We show that global and local temporal message-passing mechanisms have incomparable expressive power when applied to arbitrary temporal graphs. However, the local mechanism is strictly more expressive than the global mechanism when applied to colour-persistent temporal graphs, whose node colours are initially the same in all time points. Our theoretical findings are supported by experimental evidence, underlining practical implications of our analysis.</p> <p><strong>Updates</strong></p> <p>Since this talk was presented it the work was published at AAAI <a class="citation" href="#Wałęga_Rawson_2025">(Wałęga &amp; Rawson, 2025)</a></p>]]></content><author><name></name></author><category term="talks"/><category term="ongoing-work"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Przemyslaw Walega]]></summary></entry><entry><title type="html">Understanding Model Calibration - A gentle &amp;amp; visual introduction to classic calibration and the expected calibration error + alternative definitions of calibration</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/understanding-model-calibration/" rel="alternate" type="text/html" title="Understanding Model Calibration - A gentle &amp;amp; visual introduction to classic calibration and the expected calibration error + alternative definitions of calibration"/><published>2024-11-20T10:30:00+00:00</published><updated>2024-11-20T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/understanding-model-calibration</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/understanding-model-calibration/"><![CDATA[<p><strong><a href="https://majapavlo.github.io/">Maja Pavlovic</a></strong> will be presenting and discussing the the works surrounding model calibration.</p> <p><strong><em>Abstract</em></strong></p> <p>To be considered reliable, a model must be calibrated so that its confidence in each decision closely reflects its true outcome. In this blogpost we’ll take a look at the most commonly used definition for calibration and then dive into the most popular evaluation measure for model calibration. We’ll then cover some of the drawbacks of this measure and how these surfaced the need for additional notions of calibration, which require their own new evaluation measures. This post is not intended to be an in-depth dissection of all works on calibration, nor does it focus on how to calibrate models. Instead, it is meant to provide a gentle introduction to the different notions and their evaluation measures as well as to re-highlight some issues with a measure that is still widely used to evaluate calibration.</p> <p><strong>Updates</strong></p> <p>Since this talk was presented it the work was turn into a <a href="https://iclr-blogposts.github.io/2025/blog/calibration/">blog post</a> <a class="citation" href="#pavlovic2025understandingmodelcalibration">(Pavlovic, 0AD)</a> and <strong>Won</strong> Best Blog Post at <a href="https://iclr-blogposts.github.io/2025/about/">ICLR 2025</a>.</p>]]></content><author><name></name></author><category term="talks"/><category term="ongoing-work"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Maja Pavlovic]]></summary></entry><entry><title type="html">Neural Network Compression - The Functional Perspective (+ Extensions)</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/functional-perspective/" rel="alternate" type="text/html" title="Neural Network Compression - The Functional Perspective (+ Extensions)"/><published>2024-10-09T10:30:00+00:00</published><updated>2024-10-09T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/functional-perspective</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/functional-perspective/"><![CDATA[<p><strong><a href="https://openreview.net/profile?id=~Israel_Mason-Williams1">Israel Mason-Williams</a></strong> will be presenting and discussing the paper Neural Network Compression: The Functional Perspective (+ Extensions) <a class="citation" href="#mason-williams2024neural">(Mason-Williams, 2024)</a> <a class="citation" href="#mason-williams2024knowledge">(Mason-Williams et al., 2024)</a>.</p> <p><strong><em>Abstract</em></strong></p> <p>Compression techniques, such as Knowledge distillation, Pruning, and Quantization reduce the computational costs of model inference and enable on-edge machine learning. The efficacy of compression methods is often evaluated through the proxy of accuracy and loss to understand similarity of the compressed model. This study aims to explore the functional divergence between compressed and uncompressed models. The results indicate that Quantization and Pruning create models that are functionally similar to the original model. In contrast, Knowledge distillation creates models that do not functionally approximate their teacher models. The compressed model resembles the dissimilarity of function observed in independently trained models. Therefore, it is verified, via a functional under- standing, that Knowledge distillation is not a compression method. Thus, leading to the definition of Knowledge distillation as a training regulariser given that no knowledge is distilled from a teacher to a student.</p>]]></content><author><name></name></author><category term="talks"/><category term="publised-paper"/><category term="invited-talk"/><summary type="html"><![CDATA[Presented by Israel Mason-Williams]]></summary></entry><entry><title type="html">Probing Neural Networks With Finite Automata</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/fsa-rnn/" rel="alternate" type="text/html" title="Probing Neural Networks With Finite Automata"/><published>2024-10-09T10:30:00+00:00</published><updated>2024-10-09T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/fsa-rnn</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/fsa-rnn/"><![CDATA[<p><strong><a href="https://fredrikdahlqvist.wordpress.com/">Fredrik Dahlqvist</a></strong> will be presenting and discussing the paper: Finite state automata and simple recurrent networks <a class="citation" href="#cleeremans1989finite">(Cleeremans et al., 1989)</a></p> <p><strong><em>Abstract</em></strong></p> <p>We explore a network architecture introduced by Elman (1988) for predicting successive elements of a sequence. The network uses the pattern of activation over a set of hidden units from time-step t−1, together with element t, to predict element t + 1. When the network is trained with strings from a particular finite-state grammar, it can learn to be a perfect finite-state recognizer for the grammar. When the network has a minimal number of hidden units, patterns on the hidden units come to correspond to the nodes of the grammar, although this correspondence is not necessary for the network to act as a perfect finite-state recognizer. We explore the conditions under which the network can carry information about distant sequential contingencies across intervening elements. Such information is maintained with relative ease if it is relevant at each intermediate step; it tends to be lost when intervening elements do not depend on it. At first glance this may suggest that such networks are not relevant to natural language, in which dependencies may span indefinite distances. However, embeddings in natural language are not completely independent of earlier information. The final simulation shows that long distance sequential contingencies can be encoded by the network even if only subtle statistical properties of embedded strings depend on the early information.</p>]]></content><author><name></name></author><category term="talks"/><category term="publised-paper"/><summary type="html"><![CDATA[Presented by Fredrik Dahlqvist]]></summary></entry></feed>