<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://qmul-rg-fundamentals-of-ai.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://qmul-rg-fundamentals-of-ai.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-29T14:43:38+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Deep Learning is Not So Mysterious or Different</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/deep-learning-is-not-so-mysterious-or-different/" rel="alternate" type="text/html" title="Deep Learning is Not So Mysterious or Different"/><published>2025-04-09T10:30:00+00:00</published><updated>2025-04-09T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/deep-learning-is-not-so-mysterious-or-different</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/deep-learning-is-not-so-mysterious-or-different/"><![CDATA[<p><strong><a href="https://gmw99.github.io/">Gabryel Mason-Williams</a></strong> will presenting and dicussing the paper: Deep Learning is Not So Mysterious or Different <a class="citation" href="#wilson2025deeplearningmysteriousdifferent">(Wilson, 2025)</a></p> <p><strong><em>Abstract</em></strong></p> <p>Deep neural networks are often seen as different from other model classes by defying conventional notions of generalization. Popular examples of anomalous generalization behaviour include benign overfitting, double descent, and the success of overparametrization. We argue that these phenomena are not distinct to neural networks, or particularly mysterious. Moreover, this generalization behaviour can be intuitively understood, and rigorously characterized using long-standing generalization frameworks such as PAC-Bayes and countable hypothesis bounds. We present soft inductive biases as a key unifying principle in explaining these phenomena: rather than restricting the hypothesis space to avoid overfitting, embrace a flexible hypothesis space, with a soft preference for simpler solutions that are consistent with the data. This principle can be encoded in many model classes, and thus deep learning is not as mysterious or different from other model classes as it might seem. However, we also highlight how deep learning is relatively distinct in other ways, such as its ability for representation learning, phenomena such as mode connectivity, and its relative universality.</p>]]></content><author><name></name></author><category term="talks"/><category term="arxiv-paper"/><summary type="html"><![CDATA[Presented by Gabryel Mason-Williams]]></summary></entry><entry><title type="html">The Biophysical Principles Underlying Computation in Neural Substrates</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/the-biophysical-principles-underlying-computation-in-neural-substrates/" rel="alternate" type="text/html" title="The Biophysical Principles Underlying Computation in Neural Substrates"/><published>2025-03-12T10:30:00+00:00</published><updated>2025-03-12T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/the-biophysical-principles-underlying-computation-in-neural-substrates</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/the-biophysical-principles-underlying-computation-in-neural-substrates/"><![CDATA[<p><strong><a href="https://iranroman.github.io/">Iran Roman</a></strong> will presenting and dicussing the following:</p> <p><strong><em>Abstract</em></strong></p> <p>This presentation offers an overview of NeuroAI’s development, starting with seminal biophysical models such as the Hodgkin-Huxley equations, which elucidate the ionic mechanisms underlying neuronal action potentials. We then discuss the Wilson-Cowan model, capturing the interactions between excitatory and inhibitory neuronal populations. Advancements in the 2010s used recurrent neural networks to paralleling complex computations observed in both macaque and RNNs. We then discuss dynamical systems approaches, emphasizing their efficacy in modeling the temporal evolution of human brain activity, including unsupervised Hebbian Learning. Finally, we explore bifurcation theory’s role in identifying critical parameters that govern perception-action coupling within neural substrates, illustrating how minor variations can lead to significant shifts in neural computation.</p> <p><strong>Related Work</strong></p> <p><a class="citation" href="#mante2013context">(Mante et al., 2013)</a></p> <p><a class="citation" href="#zemlianova2024dynamical">(Zemlianova et al., 2024)</a></p> <p><a class="citation" href="#roman2023hebbian">(Roman et al., 2023)</a></p> <p><a class="citation" href="#driscoll2024flexible">(Driscoll et al., 2024)</a></p>]]></content><author><name></name></author><category term="talks"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Iran Roman]]></summary></entry><entry><title type="html">Approaching Deep Learning through the Spectral Dynamics of Weights</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/approaching-deep-learning-through-the-spectral-dynamics-of-weights/" rel="alternate" type="text/html" title="Approaching Deep Learning through the Spectral Dynamics of Weights"/><published>2025-02-26T10:30:00+00:00</published><updated>2025-02-26T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/approaching-deep-learning-through-the-spectral-dynamics-of-weights</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/approaching-deep-learning-through-the-spectral-dynamics-of-weights/"><![CDATA[<p><strong><a href="https://www.seresearch.qmul.ac.uk/cmai/people/msandler/">Mark Sandler</a></strong> will presenting and dicussing the the paper: Approaching Deep Learning through the Spectral Dynamics of Weights <a class="citation" href="#yunis2024approachingdeeplearningspectral">(Yunis et al., 2024)</a></p> <p><strong><em>Abstract</em></strong></p> <p>We propose an empirical approach centered on the spectral dynamics of weights—the behavior of singular values and vectors during optimization—to unify and clarify several phenomena in deep learning. We identify a consistent bias in optimization across various experiments, from small-scale ``grokking’’ to large-scale tasks like image classification with ConvNets, image generation with UNets, speech recognition with LSTMs, and language modeling with Transformers. We also demonstrate that weight decay enhances this bias beyond its role as a norm regularizer, even in practical systems. Moreover, we show that these spectral dynamics distinguish memorizing networks from generalizing ones, offering a novel perspective on this longstanding conundrum. Additionally, we leverage spectral dynamics to explore the emergence of well-performing sparse subnetworks (lottery tickets) and the structure of the loss surface through linear mode connectivity. Our findings suggest that spectral dynamics provide a coherent framework to better understand the behavior of neural networks across diverse settings.</p>]]></content><author><name></name></author><category term="talks"/><category term="arxiv-paper"/><summary type="html"><![CDATA[Presented by Mark Sandler]]></summary></entry><entry><title type="html">Explaining Transformers Using Model-Based Stochastic Signal Processing</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/explaining-transformers-using-model-based-stochastic-signal-processing/" rel="alternate" type="text/html" title="Explaining Transformers Using Model-Based Stochastic Signal Processing"/><published>2025-02-12T10:30:00+00:00</published><updated>2025-02-12T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/explaining-transformers-using-model-based-stochastic-signal-processing</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/explaining-transformers-using-model-based-stochastic-signal-processing/"><![CDATA[<p><strong><a href="https://uk.linkedin.com/in/careybunks">Carey Bunks</a></strong> will presenting their ongoing work on analysing Transformers</p> <p><strong><em>Abstract</em></strong></p> <p>This talk presents a novel analysis of Transformer components based on techniques drawn from model-based stochastic signal processing.  The proposed framework offers a theoretical foundation useful for mechanistic interpretability, and also suggests practical strategies for improving the performance of Transformer architectures.  Some preliminary experimental results will be presented.</p>]]></content><author><name></name></author><category term="talks"/><category term="ongoing-work"/><summary type="html"><![CDATA[Presented by Carey Bunks]]></summary></entry><entry><title type="html">NeurIPS 2024 Recap</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/neurips-recap/" rel="alternate" type="text/html" title="NeurIPS 2024 Recap"/><published>2025-01-29T10:30:00+00:00</published><updated>2025-01-29T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/neurips-recap</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2025/neurips-recap/"><![CDATA[<p><strong><a href="https://gmw99.github.io/">Gabryel Mason-Williams</a></strong> will be presenting about their time at NeurIPS 2024.</p> <p><strong><em>Abstract</em></strong></p> <p>This meeting will be a discussion on talks, papers etc, that Gabryel attend and saw that might be of interest to the group. It will be a broad range of papers and topics.</p>]]></content><author><name></name></author><category term="talks"/><category term="conference-update"/><summary type="html"><![CDATA[Presented by Gabryel Mason-Williams]]></summary></entry><entry><title type="html">Expressive Power of Temporal Message Passing</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/expressive-power-of-temporal-message-passing/" rel="alternate" type="text/html" title="Expressive Power of Temporal Message Passing"/><published>2024-12-04T10:30:00+00:00</published><updated>2024-12-04T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/expressive-power-of-temporal-message-passing</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/expressive-power-of-temporal-message-passing/"><![CDATA[<p><strong><a href="https://sites.google.com/site/pawalega/">Przemyslaw Walega</a></strong> will be presenting Expressive Power of Temporal Message Passing <a class="citation" href="#wałęga2024expressivepowertemporalmessage">(Wałęga &amp; Rawson, 2024)</a></p> <p><strong><em>Abstract</em></strong></p> <p>Graph neural networks (GNNs) have recently been adapted to temporal settings, often employing temporal versions of the message-passing mechanism known from GNNs. We divide temporal message passing mechanisms from literature into two main types: global and local, and establish Weisfeiler-Leman characterisations for both. This allows us to formally analyse expressive power of temporal message-passing models. We show that global and local temporal message-passing mechanisms have incomparable expressive power when applied to arbitrary temporal graphs. However, the local mechanism is strictly more expressive than the global mechanism when applied to colour-persistent temporal graphs, whose node colours are initially the same in all time points. Our theoretical findings are supported by experimental evidence, underlining practical implications of our analysis.</p> <p><strong>Updates</strong></p> <p>Since this talk was presented it the work was published at AAAI <a class="citation" href="#Wałęga_Rawson_2025">(Wałęga &amp; Rawson, 2025)</a></p>]]></content><author><name></name></author><category term="talks"/><category term="ongoing-work"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Przemyslaw Walega]]></summary></entry><entry><title type="html">Understanding Model Calibration - A gentle &amp;amp; visual introduction to classic calibration and the expected calibration error + alternative definitions of calibration</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/understanding-model-calibration/" rel="alternate" type="text/html" title="Understanding Model Calibration - A gentle &amp;amp; visual introduction to classic calibration and the expected calibration error + alternative definitions of calibration"/><published>2024-11-20T10:30:00+00:00</published><updated>2024-11-20T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/understanding-model-calibration</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/understanding-model-calibration/"><![CDATA[<p><strong><a href="https://majapavlo.github.io/">Maja Pavlovic</a></strong> will be presenting and discussing the the works surrounding model calibration.</p> <p><strong><em>Abstract</em></strong></p> <p>To be considered reliable, a model must be calibrated so that its confidence in each decision closely reflects its true outcome. In this blogpost we’ll take a look at the most commonly used definition for calibration and then dive into the most popular evaluation measure for model calibration. We’ll then cover some of the drawbacks of this measure and how these surfaced the need for additional notions of calibration, which require their own new evaluation measures. This post is not intended to be an in-depth dissection of all works on calibration, nor does it focus on how to calibrate models. Instead, it is meant to provide a gentle introduction to the different notions and their evaluation measures as well as to re-highlight some issues with a measure that is still widely used to evaluate calibration.</p> <p><strong>Updates</strong></p> <p>Since this talk was presented it the work was turn into a <a href="https://iclr-blogposts.github.io/2025/blog/calibration/">blog post</a> <a class="citation" href="#pavlovic2025understandingmodelcalibration">(Pavlovic, 0AD)</a> and <strong>Won</strong> Best Blog Post at <a href="https://iclr-blogposts.github.io/2025/about/">ICLR 2025</a>.</p>]]></content><author><name></name></author><category term="talks"/><category term="ongoing-work"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Maja Pavlovic]]></summary></entry><entry><title type="html">Neural Network Compression - The Functional Perspective (+ Extensions)</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/functional-perspective/" rel="alternate" type="text/html" title="Neural Network Compression - The Functional Perspective (+ Extensions)"/><published>2024-10-09T10:30:00+00:00</published><updated>2024-10-09T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/functional-perspective</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/functional-perspective/"><![CDATA[<p><strong><a href="https://openreview.net/profile?id=~Israel_Mason-Williams1">Israel Mason-Williams</a></strong> will be presenting and discussing the paper Neural Network Compression: The Functional Perspective (+ Extensions) <a class="citation" href="#mason-williams2024neural">(Mason-Williams, 2024)</a> <a class="citation" href="#mason-williams2024knowledge">(Mason-Williams et al., 2024)</a>.</p> <p><strong><em>Abstract</em></strong></p> <p>Compression techniques, such as Knowledge distillation, Pruning, and Quantization reduce the computational costs of model inference and enable on-edge machine learning. The efficacy of compression methods is often evaluated through the proxy of accuracy and loss to understand similarity of the compressed model. This study aims to explore the functional divergence between compressed and uncompressed models. The results indicate that Quantization and Pruning create models that are functionally similar to the original model. In contrast, Knowledge distillation creates models that do not functionally approximate their teacher models. The compressed model resembles the dissimilarity of function observed in independently trained models. Therefore, it is verified, via a functional under- standing, that Knowledge distillation is not a compression method. Thus, leading to the definition of Knowledge distillation as a training regulariser given that no knowledge is distilled from a teacher to a student.</p>]]></content><author><name></name></author><category term="talks"/><category term="publised-paper"/><category term="invited-talk"/><summary type="html"><![CDATA[Presented by Israel Mason-Williams]]></summary></entry><entry><title type="html">Probing Neural Networks With Finite Automata</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/fsa-rnn/" rel="alternate" type="text/html" title="Probing Neural Networks With Finite Automata"/><published>2024-10-09T10:30:00+00:00</published><updated>2024-10-09T10:30:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/fsa-rnn</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/fsa-rnn/"><![CDATA[<p><strong><a href="https://fredrikdahlqvist.wordpress.com/">Fredrik Dahlqvist</a></strong> will be presenting and discussing the paper: Finite state automata and simple recurrent networks <a class="citation" href="#cleeremans1989finite">(Cleeremans et al., 1989)</a></p> <p><strong><em>Abstract</em></strong></p> <p>We explore a network architecture introduced by Elman (1988) for predicting successive elements of a sequence. The network uses the pattern of activation over a set of hidden units from time-step t−1, together with element t, to predict element t + 1. When the network is trained with strings from a particular finite-state grammar, it can learn to be a perfect finite-state recognizer for the grammar. When the network has a minimal number of hidden units, patterns on the hidden units come to correspond to the nodes of the grammar, although this correspondence is not necessary for the network to act as a perfect finite-state recognizer. We explore the conditions under which the network can carry information about distant sequential contingencies across intervening elements. Such information is maintained with relative ease if it is relevant at each intermediate step; it tends to be lost when intervening elements do not depend on it. At first glance this may suggest that such networks are not relevant to natural language, in which dependencies may span indefinite distances. However, embeddings in natural language are not completely independent of earlier information. The final simulation shows that long distance sequential contingencies can be encoded by the network even if only subtle statistical properties of embedded strings depend on the early information.</p>]]></content><author><name></name></author><category term="talks"/><category term="publised-paper"/><summary type="html"><![CDATA[Presented by Fredrik Dahlqvist]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://qmul-rg-fundamentals-of-ai.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024[[read-time]] min read We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we’re introducing Gemini 1.5 Flash: a model that’s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We’re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5’s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It’s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it’s a lighter weight model than 1.5 Pro, it’s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it’s been trained by 1.5 Pro through a process called “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash’s availability and pricing.Over the last few months, we’ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we’ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We’ve improved control over the model’s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we’ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we’re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do — not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we’re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We’re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we’ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind’s mission to build AI responsibly to benefit humanity, we’ve always wanted to develop universal AI agents that can be helpful in everyday life. That’s why today, we’re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we’ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we’ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they’re being used in, and respond quickly, in conversation.With technology like this, it’s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We’ve made incredible progress so far with our family of Gemini models, and we’re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we’re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google’s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let’s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry></feed>